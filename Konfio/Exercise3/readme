I would configure it as follows:
-------------------------------
Structuring
When you are working on a large production infrastructure project using Terraform, you should follow a proper directory structure to deal with complexities that may occur in the project. It would be better if it had separate directories for different purposes.

For example, if you're using terraform in development, staging, and production environments, have separate directories for each.

dsamada@geekflare:~$ tree terraform_project/
terraform_project/
├── dev
│ ├── main.tf
│ ├── outputs.tf
│ └── variables.tf
├── modules
│ ├── ec2
│ │ ├── ec2.tf
│ │ └── main.tf
│ └── vpc
│ ├── main.tf
│ └── vpc.tf
├── prod
│ ├── main.tf
│ ├── outputs.tf
│ └── variables.tf
└── stg
├── main.tf
├── outputs.tf
└── variables.tf

6 directories, 13 files
Even the terraform configurations need to be separate because after a period of time the configurations of a growing infrastructure will become complex.

For example, you can write all your terraform tags (modules, resources, variables, outputs) inside the main.tffile itself, but having separate terraform tags for variables and outputs makes it more readable and easier to understand.
-------------------------------------------------------------------------------------
Naming Convention
Naming conventions are used in Terraform to make things easily understandable.

For example, suppose you want to create three different workspaces for different environments in a project. So instead of naming them like env1, en2, env3, you should call them like dev , stage , prick . From the name itself, it's pretty clear that there are three different workspaces for each environment.

Similar conventions should also be followed for resources, variables, modules, etc. The resource name in Terraform must start with a provider name followed by an underscore and other details.

For example, the resource name to create a terraform object for a route table in AWS would be aws_route_table.

Therefore, if you follow the naming conventions correctly, even complex codes will be easier to understand.
-----------------------------------------------------------------------------------------------------------
Use Shared Modules
It is strongly recommended to use the official Terraform modules available. There is no need to reinvent a module that already exists. Save a lot of time and pain. Terraform Registry has many modules available. Make changes to existing modules as needed.

Also, each module should focus on a single aspect of the infrastructure, such as creating an AWS EC2 instance, configuring the MySQL database, etc.

For example, if you want to use AWS VPC in your terraform code, you can use: Simple VPC

module "vpc_example_simple-vpc" {
source
= "terraform-aws-modules/vpc/aws//examples/simple-vpc"
version = "2.48.0"
}
--------------------------------------------------------------------------------------
Always back up your Terraform state files.

These files keep track of metadata and infrastructure resources. By default, these named files terraform.tfstateare stored locally within the workspace directory.

Without these files, Terraform will not be able to determine which resources are deployed to the infrastructure. Therefore, it is essential to have a backup of the state file. By default, a file with a name terraform.tfstate.backupwill be created to hold a backup copy of the state file.

dsamada@geekflare:~$ tree terraform_demo/
terraform_demo/
├── awsec2.tf
├── terraform.tfstate
└── terraform.tfstate.backup
0 directories, 3 files
If you want to store a backup state file in some other location, use -backupflag on the terraform command and provide the location path.

Most of the time, there will be multiple developers working on a project. Therefore, to give them access to the state file, it must be stored in a remote location using a terraform_remote_statedata source.

The following example will take a backup to S3.

data "terraform_remote_state" "vpc" {
backend = "s3"
config = {
bucket = “s3-terraform-bucket”
key = “vpc/terraform.tfstate"
region = “us-east-1”
   }
}
----------------------------------------------------------------
There can be several scenarios where more than one developer tries to run the terraform setup at the same time. This can lead to terraform status file corruption or even data loss. The locking mechanism helps prevent such scenarios. It makes sure that at a time, only one person is running the terraform configurations and there is no conflict.

Here is an example of locking the state file, which is located in a remote location using DynamoDB.

resource “aws_dynamodb_table” “terraform_state_lock” {
name = “terraform-locking”
read_capacity = 3
write_capacity = 3
hash_key = “LockingID”

attribute {
name = “LockingID”
type = “S”
   }

}
terraform {
backend “s3” {
bucket = “s3-terraform-bucket”
key = “vpc/terraform.tfstate”
region = “us-east-2”
dynamodb_table = “terraform-locking”
   }
}
When multiple users try to access the state file, the DynamoDB database name and primary key will be used to lock the state for consistency.

